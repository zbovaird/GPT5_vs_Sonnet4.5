# Comparison: GPT5 v2 vs v4.8.1 @ 10% Data

## üìä Executive Summary

**Purpose:** Compare original GPT5 approach (no weighting, no PCA) vs v4.8.1 (PyNNDescent, PCA, class weighting)

**Key Finding:** The classic trade-off - **GPT5 v2** achieves 11% higher accuracy but **completely fails** on minority attack detection, while **v4.8.1** detects all minority attacks but suffers from extreme precision collapse.

---

## üéØ Configuration Comparison

| Setting | GPT5 v2 | v4.8.1 | Difference |
|---------|---------|--------|------------|
| **Data Sampling** | 10% (283k samples) | 10% (283k samples) | Same ‚úÖ |
| **KNN Method** | sklearn | PyNNDescent | Different |
| **PCA** | No (77 features) | Yes (77‚Üí20 dims) | v4.8.1 uses PCA |
| **Class Weighting** | **NO** | **YES (inverse frequency)** | Major difference! |
| **k neighbors** | 2 | 2 | Same ‚úÖ |
| **Architecture** | UHG-GraphSAGE | UHG-GraphSAGE | Same ‚úÖ |
| **Hidden dims** | 64 | 64 | Same ‚úÖ |
| **Layers** | 2 | 2 | Same ‚úÖ |
| **GPU** | NVIDIA L4 (22GB) | NVIDIA L4 (22GB) | Same ‚úÖ |

---

## üèÜ Overall Performance Comparison

| Metric | GPT5 v2 | v4.8.1 | Winner | Delta |
|--------|---------|--------|--------|-------|
| **Overall Accuracy** | **97.16%** ü•á | 86.00% | GPT5 v2 | +11.2% |
| **Macro F1** | 0.595 | 0.391 | GPT5 v2 | +0.204 |
| **Weighted F1** | **0.971** ü•á | 0.894 | GPT5 v2 | +0.077 |
| **BENIGN Recall** | **98.11%** ü•á | 83.09% | GPT5 v2 | +15.0% |
| **Minority Detection** | **0%** ‚ùå | **100%** ‚úÖ | v4.8.1 | +100% |
| **Minority Precision** | N/A (0% recall) | **1-2%** ‚ùå | Both FAIL | - |

### ‚ö†Ô∏è Critical Insight:
- **GPT5 v2:** Excellent overall accuracy, but **ZERO** detection of Bot, Web Brute Force, Web XSS attacks!
- **v4.8.1:** Perfect minority recall, but **98% false positive rate** on those detections!

---

## ‚è±Ô∏è Performance & Timing Comparison

| Stage | GPT5 v2 | v4.8.1 | Winner | Speedup |
|-------|---------|--------|--------|---------|
| **Data Loading** | 37.95s (20%) | 38.32s (45%) | GPT5 v2 (tie) | ~1.0x |
| **PCA** | N/A (no PCA) | 0.14s (<1%) | v4.8.1 | N/A |
| **KNN Computation** | **102.24s** ‚ùå | **22.23s** ‚úÖ | v4.8.1 | **4.6x faster!** üöÄ |
| **Graph Construction** | 105.49s (55%) | 22.78s (27%) | v4.8.1 | **4.6x faster!** üöÄ |
| **Training** | 46.41s (24%) | 20.99s (25%) | v4.8.1 | 2.2x faster |
| **Total Epochs** | 169 epochs | 102 epochs | v4.8.1 | Converged faster |
| **Avg Epoch Time** | 0.27s | 0.21s | v4.8.1 | 1.3x faster |
| **Total Runtime** | **190.49s (3.2 min)** | **84.38s (1.4 min)** | v4.8.1 | **2.3x faster!** üöÄ |
| **Peak GPU Memory** | 1.56 GB | 1.56 GB | Tie | Same |

### üöÄ Key Performance Insights:
1. **PyNNDescent + PCA**: 4.6x faster KNN than sklearn (22s vs 102s)
2. **Overall speedup**: v4.8.1 is 2.3x faster end-to-end
3. **Training efficiency**: v4.8.1 converged in 40% fewer epochs (102 vs 169)

---

## üìà Per-Class Performance Comparison

### Major Attack Types:

| Attack Type | GPT5 v2 Recall | v4.8.1 Recall | GPT5 v2 Prec | v4.8.1 Prec | Better Recall | Better Precision |
|-------------|----------------|---------------|--------------|-------------|---------------|------------------|
| **BENIGN** | **98.11%** ‚úÖ | 83.09% | **98.38%** ‚úÖ | 99.86% | GPT5 v2 | v4.8.1 |
| **DDoS** | **96.88%** ‚úÖ | 99.89% | **99.37%** ‚úÖ | 68.27% | v4.8.1 | GPT5 v2 |
| **DoS Hulk** | **92.20%** ‚úÖ | 96.66% | **97.88%** ‚úÖ | 84.46% | v4.8.1 | GPT5 v2 |
| **DoS GoldenEye** | 91.33% | **99.39%** ‚úÖ | **98.75%** ‚úÖ | 25.59% | v4.8.1 | GPT5 v2 |
| **PortScan** | **99.09%** ‚úÖ | 98.89% | **81.10%** ‚úÖ | 81.42% | GPT5 v2 | v4.8.1 |
| **DoS slowloris** | 81.71% | **98.88%** ‚úÖ | **97.10%** ‚úÖ | 25.21% | v4.8.1 | GPT5 v2 |
| **DoS Slowhttptest** | 87.50% | **97.78%** ‚úÖ | **86.42%** ‚úÖ | 57.89% | v4.8.1 | GPT5 v2 |

### Minority Attack Types (Critical for IDS):

| Attack Type | GPT5 v2 Recall | v4.8.1 Recall | GPT5 v2 Prec | v4.8.1 Prec | Winner |
|-------------|----------------|---------------|--------------|-------------|--------|
| **Bot** | **0.00%** ‚ùå | **100.0%** ‚úÖ | 0% | **1.95%** ‚ö†Ô∏è | v4.8.1 (detects!) |
| **FTP-Patator** | **42.52%** ‚ùå | **98.41%** ‚úÖ | **100%** ‚úÖ | 24.70% | v4.8.1 (recall) |
| **SSH-Patator** | **45.88%** ‚ùå | **86.25%** ‚úÖ | **100%** ‚úÖ | 12.68% | v4.8.1 (recall) |
| **Web Brute Force** | **0.00%** ‚ùå | **30.00%** ‚úÖ | 0% | 7.59% | v4.8.1 (detects!) |
| **Web XSS** | **0.00%** ‚ùå | **100.0%** ‚úÖ | 0% | **2.40%** ‚ö†Ô∏è | v4.8.1 (detects!) |
| **Heartbleed** | 0% | 0% | N/A | N/A | Tie (both fail) |
| **Infiltration** | 0% | 0% | N/A | N/A | Tie (both fail) |

---

## üîç Detailed Analysis

### 1. **The Minority Detection Paradox**

**GPT5 v2 (No Weighting):**
- ‚úÖ **Pros:** Excellent overall accuracy (97.16%), very high BENIGN precision
- ‚ùå **Cons:** Completely misses Bot, Web Brute Force, Web XSS (0% recall)
- **Root Cause:** With no class weighting, the model optimizes for the dominant BENIGN class (80% of data)

**v4.8.1 (Inverse Frequency Weighting):**
- ‚úÖ **Pros:** Detects ALL minority attacks (100% Bot recall, 100% Web XSS recall)
- ‚ùå **Cons:** Only 1-2% precision = 98% false positive rate on minorities!
- **Root Cause:** Extreme weights (Bot: 97.28, Heartbleed: 9,435.8) make model over-predict minorities

### 2. **The Precision Collapse Problem**

**v4.8.1 Precision Analysis:**
```
Bot:       1.95% precision = For every 1 real bot, 50 false alarms!
Web XSS:   2.40% precision = For every 1 real XSS, 40 false alarms!
SSH:      12.68% precision = For every 1 real SSH attack, 7 false alarms!
FTP:      24.70% precision = For every 1 real FTP attack, 3 false alarms!
```

**This is UNACCEPTABLE for production IDS:**
- Security teams would be overwhelmed by false positives
- Real attacks would be lost in the noise
- Alert fatigue would render the system useless

### 3. **KNN Method Impact**

**PyNNDescent + PCA (v4.8.1) vs sklearn no PCA (GPT5 v2):**
- **Speed:** 4.6x faster (22s vs 102s)
- **Accuracy impact:** Hard to isolate due to class weighting difference
- **PCA effect:** 77‚Üí20 dims with 91% variance retained
- **Conclusion:** PyNNDescent proves its value for speed with minimal quality impact

---

## üí° Key Takeaways

### What Works:
1. ‚úÖ **PyNNDescent + PCA** (v4.8.1): 4.6x faster KNN with good quality
2. ‚úÖ **No class weighting** (GPT5 v2): Best for overall accuracy if minorities don't matter
3. ‚úÖ **Class weighting** (v4.8.1): Only way to detect Bot, Web XSS attacks

### What Fails:
1. ‚ùå **No class weighting** (GPT5 v2): Misses 100% of Bot, Web Brute Force, Web XSS
2. ‚ùå **Inverse frequency weighting** (v4.8.1): Precision collapse (1-2%) makes it impractical
3. ‚ùå **Neither model is production-ready** for a real IDS!

### The Fundamental Problem:
```
No Weighting (GPT5 v2):    97.16% accuracy, 0% minority detection     ‚ùå
Inverse Weighting (v4.8.1): 86.00% accuracy, 100% minority detection  
                            BUT 98% false positives                   ‚ùå
                            
                            NEITHER IS ACCEPTABLE!
```

---

## üéØ Recommendations

### Immediate Next Steps:
1. **Keep PyNNDescent + PCA** (proven 4.6x speedup with good quality)
2. **Fix class weighting** - Need dampened weights to balance recall vs precision:
   - Option A: Square root dampening: `weight = sqrt(original_weight)`
   - Option B: Log dampening: `weight = log(1 + original_weight)`
   - Option C: Capped weights: `weight = clip(original_weight, 0.1, 100)`

### Target Performance:
```
Ideal IDS Model:
- Overall accuracy:     93-96% (acceptable vs 97% GPT5 v2)
- BENIGN recall:        92-95% (vs 98% GPT5 v2, 83% v4.8.1)
- Bot recall:           80-95% (vs 0% GPT5 v2, 100% v4.8.1)
- Bot precision:        50-80% (vs 0% GPT5 v2, 2% v4.8.1) ‚Üê KEY FIX!
- Total time:           ~2-3 minutes (proven by v4.8.1)
```

### Architecture Decision:
- **Winner:** v4.8.1's architecture (PyNNDescent + PCA + weighting)
- **Fix needed:** Dampened class weights to balance recall/precision
- **Expected:** v4.8.2/v4.8.3 with dampened weights should achieve optimal balance!

---

## üìä Summary Tables

### Speed Comparison:
| Component | GPT5 v2 | v4.8.1 | Speedup |
|-----------|---------|--------|---------|
| KNN | 102.24s | 22.23s | **4.6x** üöÄ |
| Total | 190.49s | 84.38s | **2.3x** üöÄ |

### Accuracy Comparison:
| Metric | GPT5 v2 | v4.8.1 | Better |
|--------|---------|--------|--------|
| Overall | **97.16%** | 86.00% | GPT5 v2 |
| BENIGN Recall | **98.11%** | 83.09% | GPT5 v2 |
| Bot Recall | **0%** | **100%** | v4.8.1 |
| Bot Precision | 0% | **2%** | v4.8.1 (both terrible!) |

### The Trade-off:
```
                        Accuracy    Minority Detection    Speed    Production Ready?
GPT5 v2 (no weight):    ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ      ‚òÜ‚òÜ‚òÜ‚òÜ‚òÜ                ‚òÖ‚òÖ‚òÖ‚òÜ‚òÜ    NO (misses attacks)
v4.8.1 (inverse):       ‚òÖ‚òÖ‚òÖ‚òÜ‚òÜ      ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ (recall)        ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ    NO (98% false positives)
                                   ‚òÜ‚òÜ‚òÜ‚òÜ‚òÜ (precision)

Needed (v4.8.2+):       ‚òÖ‚òÖ‚òÖ‚òÖ‚òÜ      ‚òÖ‚òÖ‚òÖ‚òÖ‚òÜ (both)          ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ    YES! üéØ
```

---

## üèÅ Conclusion

**Neither model is production-ready, but v4.8.1's architecture is superior.**

**GPT5 v2** achieves excellent accuracy but is fundamentally flawed for IDS applications - it **cannot detect** Bot, Web Brute Force, or Web XSS attacks (0% recall). This makes it useless for security monitoring.

**v4.8.1** proves that:
1. ‚úÖ PyNNDescent + PCA work excellently (4.6x speedup)
2. ‚úÖ Class weighting is necessary to detect minority attacks
3. ‚ùå But inverse frequency weighting is too extreme (1-2% precision)

**Next step:** v4.8.2/v4.8.3 with **dampened class weights** should achieve the optimal balance:
- High overall accuracy (~94-96%)
- Good minority recall (80-95%)
- Acceptable precision (50-80%)
- Fast runtime (~2-3 min)

**Winner of architecture choices:** v4.8.1 (PyNNDescent + PCA + weighting)  
**Winner of accuracy (current):** GPT5 v2 (but unusable for IDS)  
**Winner of speed:** v4.8.1 (2.3x faster)  
**Future winner:** v4.8.2/v4.8.3 (dampened weighting) üéØ

